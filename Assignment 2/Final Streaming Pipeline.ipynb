{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56c14c1-c61c-4fa2-a0bc-a7da25b3654e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit, from_json, explode, split, concat, col, lit, countDistinct, dense_rank, desc, row_number\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, LongType, StringType, DoubleType\n",
    "from time import sleep\n",
    "from pyspark.sql import Window\n",
    "\n",
    "sparkConf = SparkConf()\n",
    "sparkConf.setMaster(\"spark://spark-master:7077\")\n",
    "sparkConf.setAppName(\"Assignment 2 Streaming\")\n",
    "sparkConf.set(\"spark.driver.memory\", \"2g\")\n",
    "sparkConf.set(\"spark.executor.cores\", \"1\")\n",
    "sparkConf.set(\"spark.driver.cores\", \"1\")\n",
    "\n",
    "# create the spark session, which is the entry point to Spark SQL engine.\n",
    "spark = SparkSession.builder.config(conf=sparkConf).getOrCreate()\n",
    "\n",
    "# set up the gcp connection\n",
    "\n",
    "conf = spark.sparkContext._jsc.hadoopConfiguration()\n",
    "conf.set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "conf.set(\"fs.AbstractFileSystem.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "\n",
    "# specify the temporary bucket\n",
    "\n",
    "bucket = \"gs://de_2024_574440/temp_de2024\"\n",
    "spark.conf.set('temporaryGcsBucket', bucket)\n",
    "\n",
    "#  Google Storage File Path\n",
    "gsc_file_path = 'gs://de_2024_574440/data/data_genre24_top5.csv'  \n",
    "\n",
    "# load and clean the top5 per genre in 2024 dataset \n",
    "\n",
    "df_24 = spark.read.format(\"csv\").option(\"header\", \"true\") \\\n",
    "       .load(gsc_file_path)\n",
    "\n",
    "df_24 = df_24.withColumn(\"averageRating\", col(\"averageRating\").cast(\"float\")) \\\n",
    "    .withColumn(\"releaseYear\", col(\"releaseYear\").cast(\"integer\")) \\\n",
    "    .withColumn(\"numVotes\", col(\"numVotes\").cast(\"integer\"))\n",
    "\n",
    "df_24 = df_24.drop(\"year_genre_rank\")\n",
    "\n",
    "# creat the schema for streaming data\n",
    "\n",
    "dataSchema = StructType(\n",
    "        [StructField(\"id\", StringType(), True),\n",
    "         StructField(\"title\", StringType(), True),\n",
    "         StructField(\"type\", StringType(), True),\n",
    "         StructField(\"genres\", StringType(), True),\n",
    "         StructField(\"averageRating\", StringType(), True),\n",
    "         StructField(\"numVotes\", StringType(), True),\n",
    "         StructField(\"releaseYear\", StringType(), True)\n",
    "         ])\n",
    "\n",
    "# define the foreachbatch function\n",
    "\n",
    "def write_to_bigquery(batch_df, batch_id):\n",
    "\n",
    "    # make initial transformations to get it into a dataframe form\n",
    "    \n",
    "    sdf = batch_df.selectExpr(\"CAST(value AS STRING)\")\n",
    "\n",
    "    df = sdf.withColumn(\"data\", from_json(col(\"value\"), dataSchema)) \\\n",
    "            .select(\"data.*\")  \n",
    "\n",
    "    #filter on moves and tv shows only\n",
    "    \n",
    "    df = df.where((df.type==\"movie\") | (df.type==\"tvSeries\"))\n",
    "\n",
    "    #eemove rows with null values for key columns\n",
    "    df = df.filter(df.averageRating != 'NULL') \\\n",
    "         .filter(df.genres != 'NULL') \\\n",
    "         .filter(df.releaseYear != 'NULL')\n",
    "    \n",
    "    #transform strings into float and integers\n",
    "    df = df.withColumn(\"averageRating\", col(\"averageRating\").cast(\"float\")) \\\n",
    "        .withColumn(\"releaseYear\", col(\"releaseYear\").cast(\"integer\")) \\\n",
    "        .withColumn(\"numVotes\", col(\"numVotes\").cast(\"integer\"))\n",
    "    \n",
    "    #Clean genres, so that only the main genre is available per row\n",
    "    df = df.withColumn(\"genre_t\", split(df.genres, ', ')).drop(\"genres\") \\\n",
    "         .withColumn(\"one_genre\", col(\"genre_t\").getItem(0)).drop(\"genre_t\")\n",
    "\n",
    "    #Merge with the dataset from the bucket\n",
    "\n",
    "    df_merged = df_24.union(df)\n",
    "        \n",
    "    #Create windows and rank by year and genre/year\n",
    "\n",
    "    window=Window.partitionBy(\"one_genre\").orderBy(desc(\"averageRating\"))\n",
    "\n",
    "    window_year = Window.orderBy(desc(\"averageRating\"))\n",
    "    \n",
    "    df_transformed = df_merged.withColumn(\"year_genre_rank\", row_number().over(window)) \\\n",
    "        .withColumn(\"year_rank\", dense_rank().over(window_year))\n",
    "\n",
    "    #select only the top 5 ranked movies per genre in a year\n",
    "    \n",
    "    df_filtered = df_transformed.filter(df_transformed.year_genre_rank < 6)\n",
    "    \n",
    "    # write to BigQuery\n",
    "    df_filtered.write \\\n",
    "        .format(\"bigquery\") \\\n",
    "        .option(\"table\", \"still-entity-435508-a1.Movies.genre24_top5\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .save()\n",
    "\n",
    "    # write to Google Bucket\n",
    "    df_filtered.write.mode(\"overwrite\").option(\"header\", \"true\").csv(gsc_file_path)\n",
    "\n",
    "\n",
    "streaming_df = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka1:9093\") \\\n",
    "    .option(\"failOnDataLoss\", \"false\") \\\n",
    "    .option(\"subscribe\", \"IMDB_C\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load()\n",
    "\n",
    "# streaming query with foreachbatch\n",
    "query = streaming_df.writeStream \\\n",
    "    .foreachBatch(write_to_bigquery) \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .start()\n",
    "\n",
    "query.awaitTermination()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc1e2fb9-6134-4b69-880c-cc1c2799c327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the spark context\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
